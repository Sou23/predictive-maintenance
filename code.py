# -*- coding: utf-8 -*-
"""Code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wUXi7XaMKUfWY4wCaZtrf4tLTEPcwXjA
"""

import numpy as np
import tensorflow as tf
from keras.models import Sequential
from keras import models
from keras.layers import Dense
from tensorflow import keras
import matplotlib.pyplot as plt
import pandas as pd

from google.colab import files
uploaded = files.upload()

from numpy import genfromtxt
data = genfromtxt('data.csv', delimiter=';')

valid_data = 0

for i in range(1, data.shape[0]):
  if np.isnan(data[:,0][i]):
    data[:,0][i] = data[:,0][i-1]+0.01
  if np.isnan(data[:,2][i]):
    data[:,2][i]=data[:,2][i-1]+0.01
  if data[i,2] < 60 and data[i,1] < 75 and data[i,0] < 80:
    valid_data = valid_data + 1

data_train = np.zeros((1, 4))
data_test = np.zeros((1, 4))

for i in range(1,data[:,2].size):
  if data[i,2] < 60 and data[i,1] < 75 and data[i,0] < 80: 
    d = np.array([data[i,0],data[i,1],data[i,2],1], dtype = object).reshape(1,4)
    data_train = np.append(data_train, d, axis=0)
  else:
    d = np.array([data[i,0],data[i,1],data[i,2],0], dtype = object).reshape(1,4)
    data_test = np.append(data_test, d, axis=0)
data_test = np.delete(data_test,0,0)
data_train = np.delete(data_train,0,0)

x = np.append(data_train,data_test,axis=0) â¸
np.savetxt("pd.csv", x, delimiter=",")

elevator = pd.read_csv('pd.csv', header=None, names=["Ball-bearing", 
                                                     "Humidity", 
                                                     "Vibration",
                                                     "Status"])

elevator

import matplotlib.pyplot as plt
import seaborn as sns

sns.pairplot(data=elevator,hue="Status")
plt.show()

np.random.shuffle(data_train)
np.random.shuffle(data_test)
t = int(data_train[:,0].size/5)
v = int(data_test[:,0].size/5)
train = np.concatenate((data_train[t:,:],data_test[v:,:])).astype('float32')
test = np.concatenate((data_train[:t,:],data_test[:v,:])).astype('float32')
early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss',
                                              patience=1,
                                              mode='min')

model1 = Sequential()
model1.add(Dense(3, input_dim=3, activation='relu',
          kernel_initializer=keras.initializers.RandomNormal(stddev=0.01),
          bias_initializer=keras.initializers.RandomNormal(stddev=0.01)))
model1.add(Dense(2, activation='relu',
          kernel_initializer=keras.initializers.RandomNormal(stddev=0.01),
          bias_initializer=keras.initializers.RandomNormal(stddev=0.01)))
model1.add(Dense(1, activation='sigmoid',
          kernel_initializer=keras.initializers.RandomNormal(stddev=0.01),
          bias_initializer=keras.initializers.RandomNormal(stddev=0.01)))
model1.compile(loss='MeanSquaredError', optimizer= 'Adam', metrics=['accuracy'])
history1 = model1.fit(train[:,0:3],train[:,3], epochs = 50,
                      validation_data=(test[:,0:3],test[:,3]),
                      batch_size = 256, shuffle = True,
                      callbacks=early_stop)

model2 = Sequential()
model2.add(Dense(3, input_dim=3, activation='sigmoid',
          kernel_initializer=keras.initializers.RandomNormal(stddev=0.01),
          bias_initializer=keras.initializers.RandomNormal(stddev=0.01)))
model2.add(Dense(3, activation='sigmoid',
          kernel_initializer=keras.initializers.RandomNormal(stddev=0.01),
          bias_initializer=keras.initializers.RandomNormal(stddev=0.01)))
model2.add(Dense(1, activation='sigmoid',
          kernel_initializer=keras.initializers.RandomNormal(stddev=0.01),
          bias_initializer=keras.initializers.RandomNormal(stddev=0.01)))
model2.compile(loss='MeanSquaredError', optimizer= 'Adam', metrics=['accuracy'])
history2 = model2.fit(train[:,0:3],train[:,3], epochs = 50, 
                      validation_data=(test[:,0:3],test[:,3]), 
                      batch_size = 256, shuffle = True,
                      callbacks=early_stop)

#  "Accuracy"
plt.plot(history1.history['accuracy'])
plt.plot(history2.history['accuracy'])
plt.legend(['Model 1','Model 2'])
plt.title('Models accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.show()

#  "Validation Accuracy"
plt.plot(history1.history['val_accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.legend(['Model 1','Model 2])
plt.title('Models Validation Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.show()

from sklearn.cluster import MiniBatchKMeans
features = np.concatenate((data_train[:,0:3], data_test[:,0:3])).astype('float32')
kmeans = MiniBatchKMeans(n_clusters = 2,
                         batch_size = 124,
                         max_iter = 100) 
kmeans.fit(features)
centroids = kmeans.cluster_centers_
labels = kmeans.labels_

colors = ["b.","r."]
for i in range(1000):
    plt.plot(features[i][0], features[i][1], colors[labels[i]], markersize = 10)

plt.scatter(centroids[:, 0],centroids[:, 1], marker = "x", s=150, linewidths = 5, zorder = 10)
plt.show()

l = np.concatenate((data_train[:,3], data_test[:,3])).astype('float32')
c = 0
for i in range(l.size):
  if labels[i]==1 and l[i] == 1:
    c = c + 1
c

o = 0
z = 0
for i in range(features.shape[0]):
  if kmeans.predict(features[i].reshape(1,3)) == 0:
    z = z + 1
o = features.shape[0]-z

print('Cluster One: ', z,' | Cluster Two: ', o)